{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Solutions to Pandas exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook contains the solutions to some exercises about Pandas that didn't (or couldn't) have a test.\n",
    "Exercises are grouped by the same main sections of the [Pandas notebook](../24_library_pandas.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Working with Pandas `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "A test is provided for each exercise in this section.\n",
    "You can check your solution directly in the main notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang = pd.DataFrame()\n",
    "\n",
    "for ticker in ['fb', 'aapl', 'amzn', 'nflx', 'goog']:\n",
    "    df = pd.read_csv(f'../data/02/exercises/{ticker}.csv')\n",
    "    \n",
    "    # make the ticker the first column\n",
    "    df.insert(0, 'ticker', ticker.upper())\n",
    "    \n",
    "    # append the new data\n",
    "    faang = pd.concat([faang, df])\n",
    "\n",
    "# just have a look at the resulting dataset\n",
    "faang.head(-5)\n",
    "    \n",
    "# faang.to_csv('faang.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang = faang.assign(\n",
    "    date=lambda x: pd.to_datetime(x.date),\n",
    "    volume=lambda x: x.volume.astype(int)\n",
    ").sort_values(\n",
    "    ['date', 'ticker']\n",
    ")\n",
    "\n",
    "faang.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.nsmallest(7, 'volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "quakes = pd.read_csv('../data/03/exercises/earthquakes.csv')\n",
    "faang = pd.read_csv('../data/03/exercises/faang.csv', index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.query(\n",
    "    \"parsed_place == 'Japan' and magType == 'mb' and mag >= 4.9\"\n",
    ")[['mag', 'magType', 'place']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.query(\"magType == 'ml'\").assign(\n",
    "    mag_bin=lambda x: pd.cut(x.mag, np.arange(0, 10))\n",
    ").mag_bin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "***Note:** we replaced the aggregation operators (or callbacks) `np.mean`, `np.max`, etc. with their string equivalents. This is because explicit callbacks are deprecated in Pandas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.groupby('ticker').resample('1M').agg(\n",
    "    {\n",
    "        'open': 'mean',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'mean',\n",
    "        'volume': 'sum'\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
