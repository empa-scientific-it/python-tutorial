{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "  - [References](#References)\n",
    "  - [Introduction to Libraries](#Introduction-to-Libraries)\n",
    "    - [Why are libraries important?](#Why-are-libraries-important?)\n",
    "    - [Finding the right Library](#Finding-the-right-Library)\n",
    "      - [What is Pandas?](#What-is-Pandas?)\n",
    "      - [Why We Need Pandas with Python](#Why-We-Need-Pandas-with-Python)\n",
    "      - [How to use a library](#How-to-use-a-library)\n",
    "        - [Installing a library](#Installing-a-library)\n",
    "        - [Importing the library](#Importing-the-library)\n",
    "        - [Accessing its functions](#Accessing-its-functions)\n",
    "        - [Getting help and inspiration](#Getting-help-and-inspiration)\n",
    "    - [First step: Data import and exploration](#First-step:-Data-import-and-exploration)\n",
    "    - [Exercise reading in data](#Exercise-reading-in-data)\n",
    "    - [Playground](#Playground)\n",
    "      - [Data exploration](#Data-exploration)\n",
    "  - [Building the plot from scratch](#Building-the-plot-from-scratch)\n",
    "    - [Finding the limits](#Finding-the-limits)\n",
    "    - [Cleaning missing values](#Cleaning-missing-values)\n",
    "      - [Exercise: Complete Happiness](#Exercise:-Complete-Happiness)\n",
    "    - [Adding regional indicator](#Adding-regional-indicator)\n",
    "      - [Exercise: Final Happiness](#Exercise:-Final-Happiness)\n",
    "    - [Plotting basic scatter plot](#Plotting-basic-scatter-plot)\n",
    "    - [Making frames per year](#Making-frames-per-year)\n",
    "      - [Adding slider bar for time scale](#Adding-slider-bar-for-time-scale)\n",
    "    - [Adding pause-play button](#Adding-pause-play-button)\n",
    "    - [Using bubble size as a variable](#Using-bubble-size-as-a-variable)\n",
    "    - [Classify into categories](#Classify-into-categories)\n",
    "      - [Exercise Frames with category](#Exercise-Frames-with-category)\n",
    "      - [Bonus Exercise Fixing a library](#Bonus-Exercise-Fixing-a-library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [Guide  to Animated Bubble Charts](https://www.kaggle.com/code/aashita/guide-to-animated-bubble-charts-using-plotly/notebook) using Plotly.\n",
    "* World Happiness Report [dataset](https://www.kaggle.com/datasets/unsdsn/world-happiness).\n",
    "* [Intro to Animations](https://plot.ly/python/animations/) in Plotly.\n",
    "* Create animations online [Stack Overflow](https://stackoverflow.com/questions/45780920/plotly-icreate-animations-offline-on-jupyter-notebook).\n",
    "* [Adding Sliders](https://plot.ly/python/gapminder-example/) to Animations in Plotly.\n",
    "* [Bubbly package](https://github.com/AashitaK/bubbly) for plotting interactive and animated bubble charts using Plotly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf21b194b3a4210fcd20580080ad8ae584e3025a"
   },
   "source": [
    "# Introduction to Libraries\n",
    "\n",
    "Welcome!\n",
    "This Jupyter Notebook is designed to introduce you to the power of Python libraries.\n",
    "Here in particular we will have a look at data analysis and visualization.\n",
    "We'll be focusing on two essential libraries:\n",
    "\n",
    "-  **Pandas**: A versatile library for data manipulation and analysis.\n",
    "-  **Plotly**: A powerful tool for creating interactive and visually appealing plots.\n",
    "\n",
    "Through practical examples, you'll learn how to:\n",
    "- Load and manipulate data using Pandas DataFrames.\n",
    "- Perform data analysis tasks such as filtering, grouping, and aggregation.\n",
    "- Create informative and interactive visualizations using Plotly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why are libraries important?\n",
    "\n",
    "Python libraries are collections of pre-written code that provide reusable functions and tools for specific tasks.\n",
    "They significantly extend the capabilities of Python, allowing you to perform complex operations without writing everything from scratch.\n",
    "This saves time and effort, promotes code reusability, and helps you focus on the higher-level logic of your data analysis and visualization workflows.\n",
    "Have a look at the following plot: imagine you'd have to code every detail from scratch! Instead, we rely on the help of libraries to do most of the heavy lifting for us.\n",
    "However, there is still quite a bit to do before we can reproduce exactly this.\n",
    "Let's have a look at the following plot generated with Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9bd3a1e808d3d1251380c146f245e10f03ba387e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tutorial.my_bubbly import bubbleplot \n",
    "from plotly.offline import iplot\n",
    "path = \"data/data_exploration\"\n",
    "gapminder_indicators = pd.read_csv(path + '/gapminder.tsv', delimiter='\\t')\n",
    "\n",
    "figure = bubbleplot(dataset=gapminder_indicators, x_column='gdpPercap', y_column='lifeExp', \n",
    "    bubble_column='country', time_column='year', size_column='pop', color_column='continent', \n",
    "    x_title=\"GDP per Capita\", y_title=\"Life Expectancy\", title='Gapminder Global Indicators',\n",
    "    x_logscale=True, scale_bubble=3, height=650)\n",
    "iplot(figure, config={'scrollZoom': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph above, the size corresponds to the population of each country and the values of GDP per capital and life expectency along with the name of the country can be seen by hovering over the cursor on the bubbles.\n",
    "Imagine the work you'd have to put in to build this without any libraries.\n",
    "\n",
    "This animated bubble chart can convey a great deal of information since it can accommodate up to *six variables* in total, namely:\n",
    "- X-axis (GDP per capita)\n",
    "- Y-axis (Life Expectancy)\n",
    "- Bubbles (Countries, can be seen by hovering the cursor over the dots)\n",
    "- Time (in years)\n",
    "- Size of bubbles (Population)\n",
    "- Color of bubbles (Continents, variable can be categorical or numerical)\n",
    "\n",
    "\n",
    "Using the function `bubbleplot` from the module [`bubbly`(bubble charts with plotly)](https://github.com/AashitaK/bubbly): see references for all source material.\n",
    "Our goal is to recreate this Visualization but with a different dataset.\n",
    "For this, we have already preloaded a data file in the folder `data/introtolibraries/World-happiness-report-updated_2024.csv` which is an open data record which can be found on kaggle.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the right Library\n",
    "\n",
    "Finding the right library to use is always tricky and depends on your project requirements, the time you have available and the knowledge you may already have with libraries you already know well.\n",
    "Spending a bit of time at the beginning of a project researching and exploring some options and asking a friend for advice may be time well invested.\n",
    "For importing and exploring a dataset the most well-known Python library is Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Pandas?\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/docs/index.html) is an open-source data manipulation and analysis library for Python.\n",
    "It provides powerful data structures and functions designed to make working with structured data intuitive and efficient.\n",
    "At the heart of Pandas are two primary data structures:\n",
    "\n",
    "- **DataFrame**:\n",
    "  A two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labelled axes (rows and columns).\n",
    "  It's similar to a spreadsheet or SQL table and is generally the most commonly used Pandas object.\n",
    "- **Series**:\n",
    "  A one-dimensional labelled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.).\n",
    "\n",
    "Pandas integrates well with various other Python libraries, such as Matplotlib for plotting and NumPy for numerical computations, making it a central library in the Python data science stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why We Need Pandas with Python\n",
    "\n",
    "Python, while a powerful programming language, isn't designed specifically for data analysis.\n",
    "It lacks built-in, high-level data structures and tools that are intuitive and efficient for these tasks.\n",
    "Here's where Pandas comes in:\n",
    "\n",
    "- **Data Cleaning and Preparation**:\n",
    "  Data scientists spend a significant amount of time cleaning and preparing data.\n",
    "  Pandas simplifies these tasks with built-in functions for filtering, selecting, and manipulating data.\n",
    "- **Data Analysis**:\n",
    "  With Pandas, analyzing and exploring data is more straightforward.\n",
    "  It provides functions for aggregating, summarizing, and transforming data, making it easier to derive insights.\n",
    "- **Data Visualization**:\n",
    "  Though Pandas is not a data visualization library, it seamlessly interfaces with Matplotlib for plotting and visualizing data, allowing quick and informative visual analysis.\n",
    "- **Handling Diverse Data Types**:\n",
    "  Pandas efficiently handles a variety of data formats, including CSV, Excel files, SQL databases, and HDF5 format, making it a versatile tool for diverse data analysis needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use a library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing a library\n",
    "\n",
    "```pip install pandas```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the library\n",
    "\n",
    "Just like any code you had written yourself which is located in a different file the code for pandas needs to be imported with the statement\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "As a pre-requirement, you must have the Python package pandas installed, e.g. with your favourite package installer like `pip`.\n",
    "That is for another tutorial, we have preinstalled all the necessary libraries you will need in this environment.\n",
    "You will notice also with pandas we immediately rename the library namespace to `pd`, which is common for well-known libraries to make typing faster.\n",
    "We adopt this practice here so you have seen it before and aren't confused when it appears again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing its functions\n",
    "\n",
    "Like we said a library is just a collection of useful functions.\n",
    "Now that we have imported the library we can use all the objects within. \n",
    "As an example some useful functions in Pandas are\n",
    "\n",
    "\n",
    "| Function                         | Description                                                                            | Example                                            |\n",
    "|:---------------------------------|:---------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
    "| pd.read_csv()                    | Reads data from a CSV file and creates a `DataFrame`.                                    | pd.read_csv('data.csv')                            |\n",
    "| pd.DataFrame()                   | Creates a `DataFrame` from various data structures (lists, dictionaries, etc.).          | pd.DataFrame({'col1': [1, 2], 'col2': ['a', 'b']}) |\n",
    "| pd.DataFrame.head()                        | Displays the first few rows of the `DataFrame` (default is 5).                           | df.head()                                          |\n",
    "| pd.DataFrame.tail()                        | Displays the last few rows of the `DataFrame` (default is 5).                            | df.tail(10)                                        |\n",
    "| pd.DataFrame.info()                        | Provides a concise summary of the `DataFrame`, including data types and non-null values. | df.info()                                          |\n",
    "| pd.DataFrame.describe()                    | Generates descriptive statistics of the numerical columns in the `DataFrame`.            | df.describe()                                      |\n",
    "| pd.DataFrame['column_name']                | Selects a specific column by its name.                                                 | df['Name']                                         |\n",
    "| pd.DataFrame.loc[row_label, col_label]     | Accesses a group of rows and columns by label(s).                                      | df.loc[0, 'Age']                                   |\n",
    "| pd.DataFrame.iloc[row_index, col_index]    | Accesses a group of rows and columns by integer position(s).                           | df.iloc[2, 1]                                      |\n",
    "| pd.DataFrame.groupby('column_name')        | Groups rows based on the values in a specified column for aggregation.                 | df.groupby('Category')['Value'].mean()             |\n",
    "| pd.DataFrame.sort_values(by='column_name') | Sorts the `DataFrame` by the values in one or more columns.                              | df.sort_values(by='Date', ascending=False)         |\n",
    "| pd.DataFrame.dropna()                      | Removes rows with missing values (`NaN`).                                                | df.dropna()                                        |\n",
    "| pd.DataFrame.ffill()                       | Fills missing values by propagating the last valid observation forward to the next valid observation. | df.ffill()                                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting help and inspiration\n",
    "\n",
    "Of course one of the most important parts is to be able to understand, look up and get help on any function of a library.\n",
    "Usually, we start with some inspiration, as we gave above with the plot, there might be someone who posted something which you would like to reproduce but with a twist or you would like to change something.\n",
    "This is generally a good starting point.\n",
    "However afterwards you won't have the documentation of all the functions so you need to have the skill to find documentation and understand the requirements for function, sometimes you even need to know more about the inner workings of a functions implementations.\n",
    "\n",
    "There are several ways to access documentation.\n",
    "One way, assuming it is a well-maintained package online, is to find the documentation website.\n",
    "For pandas, this is a great place to find details on functions, and changes that may have been made with different versions and explore alternatives to a given function.\n",
    "\n",
    "[Pandas Documentation](https://pandas.pydata.org/docs/index.html)\n",
    "\n",
    "If it is a smaller library you can list all top-level functions with  `dir` as in \n",
    "```python\n",
    "print(dir(pd))\n",
    "```\n",
    "However, this will only give you top-level functions.\n",
    "\n",
    "Many environments will have code completion or you may have an AI copilot to find functions.\n",
    "And if you are struggling with a specific function you can print out the signature and the docstring with `help(function)` or `function?`.\n",
    "\n",
    "When reading the documentation you might get overwhelmed.\n",
    "Keep a lookout for the function parameters, many of which may be optional, and good documentations tend to have an example to get a feel for the function.\n",
    "\n",
    "For most of this tutorial we will give you the infos about a function that you need, however if you want to know more or need some extra information then use these tools to inform yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step: Data import and exploration\n",
    "\n",
    "Already getting your data from a file to a variable you can work with can be a headache.\n",
    "How do I read the file, how do I choose delimiters and what encoding does the file have?\n",
    "\n",
    "We will use the `pd.read_csv` function from pandas to read \"The World Happiness Report\" which is a report study on how people rate their happiness in different countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise reading in data\n",
    "\n",
    "In the cell below you should write the code that solves the first exercise:\n",
    "\n",
    "  -  Use the `path_to_happiness` which will be `data/plotly_intro/World-happiness-report-updated_2024.csv` which leads to a CSV file to read in\n",
    "  -  Read in the CSV into a dataframe and output it as `pd.DataFrame`\n",
    "  -  Because of how the `.csv`file is formated you must ensure that the encoding is latin1 `encoding='latin1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tutorial.tests.testsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def solution_read_in_dataframe(path_to_happiness: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads in a CSV file containing happiness data and returns it as a pandas DataFrame.\n",
    "\n",
    "    Instructions:\n",
    "        - Use the `path_to_happiness` which will be `data/data_exploration/World-happiness-report-updated_2024.csv`.\n",
    "        - Read in the CSV into a DataFrame using `pd.read_csv`.\n",
    "        - Ensure the encoding is set to 'latin1' as the file is formatted accordingly.\n",
    "\n",
    "    Args:\n",
    "        path_to_happiness (str): Path to the CSV file containing the happiness data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the happiness data.\n",
    "    \"\"\"\n",
    "    # Your code starts here\n",
    "    return\n",
    "    # Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happyness = pd.read_csv('data/data_exploration/World-happiness-report-updated_2024.csv', encoding='latin1')\n",
    "happyness.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use the above playground to explore the dataset using the functions test functions like:\n",
    "| Function                                      | Description                                                                                                | Example                                      |\n",
    "|:----------------------------------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------|\n",
    "| `pd.DataFrame.head()`                         | Displays the first few rows of the DataFrame (default is 5).                                               | `df.head()`                                  |\n",
    "| `pd.DataFrame.tail()`                         | Displays the last few rows of the DataFrame (default is 5).                                                | `df.tail(10)`                               |\n",
    "| `pd.DataFrame.info()`                         | Provides a concise summary of the DataFrame, including data types and non-null values.                      | `df.info()`                                  |\n",
    "| `pd.DataFrame.describe()`                      | Generates descriptive statistics of the numerical columns in the DataFrame.                                  | `df.describe()`                              |\n",
    "| `pd.DataFrame['column_name']`                 | Selects a specific column by its name.                                                                      | `df['Name']`                                 |\n",
    "| `pd.DataFrame.loc[row_label, col_label]`      | Accesses a group of rows and columns by label(s).                                                          | `df.loc[0, 'Age']`                            |\n",
    "| `pd.DataFrame.iloc[row_index, col_index]`      | Accesses a group of rows and columns by integer position(s).                                               | `df.iloc[2, 1]`                              |\n",
    "| `pd.DataFrame.groupby('column_name')`          | Groups rows based on the values in a specified column for aggregation.                                     | `df.groupby('Category')['Value'].mean()`      |\n",
    "| `pd.DataFrame.shape`                           | Returns a tuple representing the dimensionality of the DataFrame (number of rows, number of columns).      | `df.shape`                                   |\n",
    "| `pd.DataFrame.columns`                         | Returns the column labels of the DataFrame.                                                                | `df.columns`                                 |\n",
    "| `pd.DataFrame.index`                           | Returns the index (row labels) of the DataFrame.                                                           | `df.index`                                   |\n",
    "| `pd.DataFrame.dtypes`                          | Returns the data type of each column.                                                                      | `df.dtypes`                                  |\n",
    "| `pd.DataFrame.values`                          | Returns a NumPy representation of the DataFrame.                                                           | `df.values`                                  |\n",
    "| `pd.DataFrame.nunique()`                       | Returns the number of unique values in each column.                                                        | `df['City'].nunique()`                       |\n",
    "| `pd.DataFrame['column_name'].value_counts()`   | Returns a Series containing counts of unique values in a column.                                           | `df['Status'].value_counts()`                  |\n",
    "| `pd.DataFrame.sort_values(by='column_name')`   | Sorts the DataFrame by the values in a specified column.                                                   | `df.sort_values(by='Date')`                    |\n",
    "| `pd.DataFrame.sort_index()`                    | Sorts the DataFrame by its index.                                                                         | `df.sort_index()`                             |\n",
    "| `pd.DataFrame.isna().sum()`                    | Returns the number of missing (NaN) values in each column.                                                 | `df.isna().sum()`                             |\n",
    "| `pd.DataFrame.duplicated().sum()`              | Returns the number of duplicate rows in the DataFrame.                                                      | `df.duplicated().sum()`                       |\n",
    "| `pd.DataFrame['column_name'].unique()`        | Returns a NumPy array of the unique values in a column.                                                     | `df['Country'].unique()`                      |\n",
    "| `pd.DataFrame.sample(n=5)`                     | Returns a random sample of items from the DataFrame (default is 1).                                        | `df.sample(n=10)`                             |\n",
    "| `pd.DataFrame.filter(items=['col1', 'col3'])`  | Subset the dataframe columns based on the specified items (labels).                                       | `df.filter(items=['Product', 'Price'])`       |\n",
    "| `pd.DataFrame.filter(like='rate', axis=1)`     | Subset the dataframe columns based on the specified regular expression (using 'like').                    | `df.filter(like='temp', axis=1)`              |\n",
    "| `pd.DataFrame.filter(regex='^A', axis=1)`      | Subset the dataframe columns based on the specified regular expression (using 'regex').                   | `df.filter(regex='^ID', axis=1)`               |\n",
    "| `pd.DataFrame.nlargest(n, 'column_name')`     | Returns the first n rows ordered by columns in descending order.                                          | `df.nlargest(3, 'Revenue')`                   |\n",
    "| `pd.DataFrame.nsmallest(n, 'column_name')`    | Returns the first n rows ordered by columns in ascending order.                                           | `df.nsmallest(2, 'Cost')`                     |\n",
    "| `pd.DataFrame.corr(numeric_only=True)`        | Computes pairwise correlation of columns, excluding NA/null values unless the entire row/column is NA.    | `df.corr(numeric_only=True)`                  |\n",
    "| `pd.DataFrame.cov(numeric_only=True)`         | Computes pairwise covariance of columns, excluding NA/null values.                                         | `df.cov(numeric_only=True)`                   |\n",
    "| `pd.DataFrame.memory_usage(deep=True)`       | Returns the memory usage of each column in bytes. The `deep=True` argument provides a more accurate estimate.| `df.memory_usage(deep=True)`                  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "\n",
    "After playing around a bit with some functions, this is what an initial exploration of the data set could look like.\n",
    "Run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "happyness = pd.read_csv('data/data_exploration/World-happiness-report-updated_2024.csv', encoding='latin1')\n",
    "\n",
    "# Assuming your dataframe is loaded into 'df'\n",
    "df = happyness\n",
    "print(\"--- First few rows of the dataframe ---\")\n",
    "print(df.head(2))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"--- Summary information about the dataframe ---\")\n",
    "df.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"--- Descriptive statistics for numerical columns ---\")\n",
    "print(df.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"--- Checking for unique values in each column ---\")\n",
    "for col in df.columns:\n",
    "    unique_values = df[col].nunique()\n",
    "    print(f\"Column '{col}' has {unique_values} unique values.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"--- Checking for NaN (missing) values in each column ---\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Example: Checking the span of a 'year' column (if it exists)\n",
    "if 'year' in df.columns:\n",
    "    min_year = df['year'].min()\n",
    "    max_year = df['year'].max()\n",
    "    print(f\"--- Span of the 'year' column ---\")\n",
    "    print(f\"Minimum year: {min_year}\")\n",
    "    print(f\"Maximum year: {max_year}\")\n",
    "    print(f\"Year range: {max_year - min_year} years\")\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "67879155a77056411b701403cf464a2dd144eb7b"
   },
   "source": [
    "# Building the plot from scratch\n",
    "\n",
    "The plot you saw at the beginning was a plot that is part of the Plotly tutorial.\n",
    "Many parts of this tutorial are heavily inspired by this [`kaggle project`](https://www.kaggle.com/code/aashita/guide-to-animated-bubble-charts-using-plotly).\n",
    "You can find many more on that website or online available in general.\n",
    "For reference see the end of the notebook.\n",
    "Let's break down the steps we will go through in this notebook:\n",
    "\n",
    "- [Finding the limits](#Finding-the-limits)\n",
    "- [Cleaning missing values](#Cleaning-missing-values)\n",
    "- [Adding regional indicator](#Adding-regional-indicator)\n",
    "- [Plotting basic scatter plot](#Plotting-basic-scatter-plot)\n",
    "- [Making frames per year](#Making-frames-per-year)\n",
    "- [Adding pause-play button](#Adding-pause-play-button)\n",
    "- [Using bubble size as a variable](#Using-bubble-size-as-a-variable)\n",
    "- [Classify into categories](#Classify-into-categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the limits\n",
    "\n",
    "If we are plotting a function, it is important to know the order of magnitude of some of the data.\n",
    "In our case for example we want to have an animated plot over some years and it helps to know for which years we actually have data.\n",
    "In a dataframe we can e.g. use the `.min()` and `.max()` methods. \n",
    "Optionally, to understand the distribution or \"order of magnitude\" of your time values, you might want to plot out the years and check the rough distribution to identify any anomalies or gaps in the data.\n",
    "This can be done using a histogram or a line plot to visualize the frequency or trend of the time values over the range.\n",
    "\n",
    "We want to use `matplotlib.pyplot` for displaying the histogram because it has a useful function hist which does exactly that. \n",
    "\n",
    "We use the `matplotlib.pyplot as plt` library and there there is `.hist` function which will produce a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "happiness = pd.read_csv('data/data_exploration/World-happiness-report-updated_2024.csv', encoding='latin1')\n",
    "years = happiness['year'].unique()\n",
    "print(f\"Unique years in the dataset: {sorted(years)}\")\n",
    "\n",
    "df = happiness\n",
    "df['year'] = happiness['year'].astype(int)  # Ensure the years are integers\n",
    "\n",
    "# Determine the minimum and maximum years\n",
    "min_year = df['year'].min()\n",
    "max_year = df['year'].max()\n",
    "number_of_bins = max_year - min_year + 1\n",
    "\n",
    "# Plot the histogram of the years\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size for better readability\n",
    "plt.hist(df['year'], bins=number_of_bins, edgecolor='grey') # Adjust bins as needed\n",
    "plt.title('Histogram of Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning missing values\n",
    "\n",
    "Pandas provides several flexible methods for handling missing data, represented as `NaN`. \n",
    "You can identify missing values using `.isna()` or `.isnull()`, and then choose a strategy:  `.dropna()` removes rows or columns with missing values, while `.fillna()` replaces them. `.ffill` propagates the last valid observation forward to fill in the missing values.\n",
    "For example, `df.ffill` will replace a `NaN` with the value from the previous row which had a non-`Nan`value.\n",
    "You can also fill it with a specific value (like the mean, median, or constant).\n",
    "For time series data, you might use interpolation with `.interpolate()` to fill gaps.\n",
    "The best approach depends on the nature of the data and the goal of your analysis.\n",
    "\n",
    "For this step, we will try to forwardfill the dataframe:\n",
    "```python\n",
    "    cleaned_happiness = cleaned_happiness.sort_values(by=['Country name', 'year']).ffill()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Complete Happiness\n",
    "\n",
    "In this exercise, we want to complete the dataframe with missing values.\n",
    "Complete the function below to \n",
    "\n",
    "1. Fill in missing years for every country (so we have an entry for every year between 2005 and 2023 and every country).\n",
    "   Do this by initializing a DataFrame with `pd.DataFrame()` with a list.\n",
    "   Then left-merge the happiness dataframe to it with `pd.merge()`.\n",
    "2. Fill all missing values in the year 2005 with the value 1.\n",
    "   Use the `.fillna()` function.\n",
    "3. Forwardfill all the remaining years with the function `.ffill()`.\n",
    "   (To forward fill the order of the dataframe is important! Make sure to sort first.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tutorial.tests.testsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def solution_clean_dataset(happiness_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Cleans the dataset by adding missing year and country values\n",
    "\n",
    "        1. Add in missing years for every country\n",
    "        2. Fill the minimum year with values of 1\n",
    "        3. Forward fill the rest of the years\n",
    "\n",
    "    Args:\n",
    "        happiness_df : DataFrame containing the happiness data\n",
    "\n",
    "    Returns:\n",
    "        - Cleaned DataFrame with missing values filled\n",
    "    \"\"\"\n",
    "    # Your code starts here\n",
    "    return \n",
    "    # Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning is crucial in data analysis, but several pitfalls exist.\n",
    "Here's a summary of common mistakes and how to avoid them:\n",
    "\n",
    "1. Incorrectly Handling Missing Values.\n",
    "   Replacing `NaN` values with the mean can be misleading, especially with skewed data.\n",
    "   Consider using the median or more advanced imputation techniques, and understand the reason for missingness.\n",
    "   Pandas tools like `fillna()`, `dropna()`, and `interpolate()` are essential here.\n",
    "2. Removing Outliers Without Investigation.\n",
    "   Avoid automatically deleting outliers.\n",
    "   Visualize the data to determine if outliers are genuine extreme values or errors.\n",
    "   If genuine, they may be important for analysis.  Use boolean indexing with summary statistics to handle them in Pandas.\n",
    "3. Ignoring Data Types.\n",
    "   Ensure columns have the correct data type.\n",
    "   Use `df.info()` to check and convert columns with `pd.to_numeric()`, `pd.to_datetime()`, or `astype()`.\n",
    "4. Not Handling Duplicates Carefully.\n",
    "   Investigate the source of duplicate rows before removing them.\n",
    "   They may indicate data entry errors or represent significant repeated measurements.\n",
    "   Pandas provides `duplicated()` and `drop_duplicates()` for this purpose.\n",
    "5. Applying Transformations Incorrectly.\n",
    "   Scaling data without considering outliers can lead to issues.\n",
    "   If scaling is necessary, consider robust scalers (like `RobustScaler` from `scikit-learn`) that are less affected by outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding regional indicator\n",
    "\n",
    "We also want to group the countries. \n",
    "To add a regional indicator, we'll need another dataset that maps countries to their respective regions.\n",
    "We can then merge this data with our main happiness dataframe based on the 'Country name' column.\n",
    "\n",
    "Let's assume you have a CSV file named `country_region_mapping.csv` in your `data/plotly_intro/` directory with columns `'Country name'` and `'Region indicator'`.\n",
    "Then we could merge the dataframes on the country name and get a regional indicator for all the countries.\n",
    "\n",
    "Let's explore the `pd.merge` function for that.\n",
    "The merging of tables comes from SQL Table merges and if you are not familiar with those, for now, keep in mind we want to do a **left merge** with the happiness table being the left table and the region mapping the right table and we merge **on** a column which they have in common.\n",
    "\n",
    "```python\n",
    "pd.merge?\n",
    "\n",
    "Signature:\n",
    "pd.merge(\n",
    "    left: 'DataFrame | Series',\n",
    "    right: 'DataFrame | Series',\n",
    "    how: 'MergeHow' = 'inner',\n",
    "    on: 'IndexLabel | AnyArrayLike | None' = None,\n",
    "    left_on: 'IndexLabel | AnyArrayLike | None' = None,\n",
    "    right_on: 'IndexLabel | AnyArrayLike | None' = None,\n",
    "    left_index: 'bool' = False,\n",
    "    right_index: 'bool' = False,\n",
    "    sort: 'bool' = False,\n",
    "    suffixes: 'Suffixes' = ('_x', '_y'),\n",
    "    copy: 'bool | None' = None,\n",
    "    indicator: 'str | bool' = False,\n",
    "    validate: 'str | None' = None,\n",
    ") -> 'DataFrame'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Final Happiness\n",
    "\n",
    "In this exercise, we want to add the regional indicators to the dataframe\n",
    "\n",
    "  1) Merge the `region_df` with `complete_happiness_df`.\n",
    "  2) Fill in missing values with 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tutorial.tests.testsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def solution_add_regional_indicator(cleaned_happiness_df: pd.DataFrame, region_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds a regional indicator to the dataset\n",
    "\n",
    "        1. Merge the cleaned_happiness_df with region_df on the 'Country name' and 'year' columns\n",
    "        2. Fill the missing values in the 'Region indicator' column with 'Unknown'\n",
    "\n",
    "    Args:\n",
    "        cleaned_happiness_df : DataFrame containing the happiness data\n",
    "        region_df : DataFrame containing the region data\n",
    "\n",
    "    Returns:\n",
    "        - DataFrame with the regional indicator added\n",
    "    \"\"\"\n",
    "    # Your code starts here\n",
    "    return\n",
    "    # Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7bd394a0dc02c3fb4e5ec1526c35a1955f0b14e6",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Plotting basic scatter plot\n",
    "\n",
    "Scatter plots from the Plotly library are the most important thing we will be building upon.\n",
    "It magically transforms our data into a visual effect.\n",
    "For that, we have to follow the exact rules of the configuration parameters we need to follow.\n",
    "\n",
    "We work with the `iplot` function (interactive plot) from the Plotly library, which takes a figure object, which is a dictionary containing the data, the layout and the frames. \n",
    "\n",
    "```python\n",
    "figure = {\n",
    "    'data': list[trace],\n",
    "    'layout': dict,\n",
    "    'frames': list[frame],\n",
    "}\n",
    "frame = {\n",
    "    'data': list[trace],\n",
    "    'name': str,\n",
    "}\n",
    "```\n",
    "\n",
    "The data can be seen as the plot data initially, and the frames are then the animation steps.\n",
    "\n",
    "Let's first try to create a simple scatter plot, for that we populate a figure dictionary data with a trace (`dict`) which contains an array of values for `x`, an array of values for `y`, a `mode` ('markers') and an array of strings for the text which is what appears when hovered over.\n",
    "\n",
    "```python\n",
    "trace = {\n",
    "    'x': list[int],\n",
    "    'y': list[int],\n",
    "    'mode': 'markers',\n",
    "    'text': list[str],\n",
    "    'type': 'scatter'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "682e20e7d96006aeb1466c7cacbf4360c699fd6f"
   },
   "outputs": [],
   "source": [
    "# Define the dataset and the columns\n",
    "from tutorial.data_exploration_helper import get_happiness_data, get_clean_dataset_with_region\n",
    "from plotly.offline import iplot\n",
    "dataset = get_clean_dataset_with_region(get_happiness_data())\n",
    "x_column = 'Freedom to make life choices'\n",
    "y_column = 'Life Ladder'\n",
    "description_column = 'Country name'\n",
    "# time_column = 'year'\n",
    "\n",
    "\n",
    "\n",
    "# Define figure\n",
    "figure = {\n",
    "    'data': [],\n",
    "    'layout': {},\n",
    "    'frames': []\n",
    "}\n",
    "\n",
    "# Take a random year present in the dataset\n",
    "year = 2010\n",
    "\n",
    "# Make the trace\n",
    "trace = {\n",
    "    'x': list(dataset.loc[dataset['year'] == year, x_column]), \n",
    "    'y': list(dataset.loc[dataset['year'] == year, y_column]),\n",
    "    'mode': 'markers',\n",
    "    'text': list(dataset.loc[dataset['year'] == year, description_column]),\n",
    "    'type': 'scatter',\n",
    "}\n",
    "\n",
    "# Append the trace to the figure\n",
    "figure['data'] = [trace]\n",
    "\n",
    "# Plot the figure\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "810d72cd0c9581a9c89c28c14856c4db6887ef61"
   },
   "source": [
    "## Making frames per year\n",
    "\n",
    "Next, we want to make the graph animated with a slider over the years.\n",
    "This is basically the same thing as making a scatter plot for every year and adding the slider.\n",
    "So it makes sense to functionalize the trace step we did before and then fill the frames with all of the traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8033f8d68e1ba56213b706638dfc0ca43f7126ef"
   },
   "outputs": [],
   "source": [
    "from tutorial.data_exploration_helper import get_happiness_data, get_clean_dataset_with_region, get_scatter_figure\n",
    "from plotly.offline import iplot\n",
    "\n",
    "dataset = get_clean_dataset_with_region(get_happiness_data())\n",
    "x_column = 'Freedom to make life choices'\n",
    "y_column = 'Life Ladder'\n",
    "description_column = 'Country name'\n",
    "# time_column = 'year'\n",
    "figure = get_scatter_figure(dataset, x_column, y_column, description_column)\n",
    "\n",
    "def frame_by_year(dataset, year, x_column, y_column, description_column):\n",
    "    \"\"\"Make a trace for a given year\"\"\"\n",
    "    # Make a trace\n",
    "    trace = {\n",
    "        'x': list(dataset.loc[dataset['year'] == year, x_column]), \n",
    "        'y': list(dataset.loc[dataset['year'] == year, y_column]),\n",
    "        'mode': 'markers',\n",
    "        'text': list(dataset.loc[dataset['year'] == year, description_column]),\n",
    "        'type': 'scatter'\n",
    "    }\n",
    "    frame = {\n",
    "        'data': [trace],\n",
    "        'name': str(year)\n",
    "    }\n",
    "    return frame\n",
    "\n",
    "# Get the years\n",
    "years = dataset['year'].unique()\n",
    "# Sort the years\n",
    "years.sort()\n",
    "\n",
    "\n",
    "# Set timestep\n",
    "figure['frames'] = [frame_by_year(dataset, year, x_column, y_column, description_column) for year in years]\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cd91579051aec5293b189b8985e41aac1b472880"
   },
   "source": [
    "### Adding slider bar for time scale\n",
    "\n",
    "The slider needs configuring, this would require a bit of reading up what exactly you need or if you have an example you can make use of the existing functions.\n",
    "The following is heavily inspired by the module  [`bubbly`](https://github.com/AashitaK/bubbly).\n",
    "This is simply a configuration and contains only the years data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc03387500edfa18300f6be8f572699157a38264"
   },
   "outputs": [],
   "source": [
    "from tutorial.data_exploration_helper import full_clean_dataset, get_scatter_figure_with_years\n",
    "from plotly.offline import iplot\n",
    "\n",
    "dataset = full_clean_dataset()\n",
    "x_column = 'Freedom to make life choices'\n",
    "y_column = 'Life Ladder'\n",
    "description_column = 'Country name'\n",
    "figure = get_scatter_figure_with_years(dataset, x_column, y_column, description_column)\n",
    "\n",
    "\n",
    "years = dataset['year'].unique()\n",
    "years.sort()\n",
    "\n",
    "figure['layout']['sliders'] = {\n",
    "    'args': [\n",
    "        'slider.value', {\n",
    "            'duration': 400,\n",
    "            'ease': 'cubic-in-out'\n",
    "        }\n",
    "    ],\n",
    "    'initialValue': min(years),\n",
    "    'plotlycommand': 'animate',\n",
    "    'values': years,\n",
    "    'visible': True\n",
    "}\n",
    "sliders_dict = {\n",
    "    'active': 0,\n",
    "    'yanchor': 'top',\n",
    "    'xanchor': 'left',\n",
    "    'currentvalue': {\n",
    "        'font': {'size': 20},\n",
    "        'prefix': 'Year:',\n",
    "        'visible': True,\n",
    "        'xanchor': 'right'\n",
    "    },\n",
    "    'transition': {'duration': 300, 'easing': 'cubic-in-out'},\n",
    "    'pad': {'b': 10, 't': 50},\n",
    "    'len': 0.9,\n",
    "    'x': 0.1,\n",
    "    'y': 0,\n",
    "    'steps': []\n",
    "}\n",
    "\n",
    "def slider_step(year):\n",
    "    '''Creates a slider step.'''\n",
    "    \n",
    "    slider_step = {'args': [\n",
    "        [year],\n",
    "        {'frame': {'duration': 300, 'redraw': False},\n",
    "         'mode': 'immediate',\n",
    "       'transition': {'duration': 300}}\n",
    "     ],\n",
    "     'label': str(year),\n",
    "     'method': 'animate'}\n",
    "    return slider_step\n",
    "\n",
    "sliders_dict['steps'] = [slider_step(year) for year in years]\n",
    "figure['layout']['sliders'] = [sliders_dict]\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a50ba67250bd23781b19640487c8ec284fb399f4"
   },
   "source": [
    "## Adding pause-play button\n",
    "\n",
    "Buttons we give for free! (Run the above first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5097f53eecefb820ba4ccdbc28cbdf2c633e7ddc"
   },
   "outputs": [],
   "source": [
    "figure['layout']['updatemenus'] = [\n",
    "    {\n",
    "        'buttons': [\n",
    "            {\n",
    "                'args': [None, {'frame': {'duration': 500, 'redraw': False},\n",
    "                         'fromcurrent': True, 'transition': {'duration': 300, \n",
    "                                                             'easing': 'quadratic-in-out'}}],\n",
    "                'label': 'Play',\n",
    "                'method': 'animate'\n",
    "            },\n",
    "            {\n",
    "                'args': [[None], {'frame': {'duration':0, 'redraw': False}, 'mode': 'immediate',\n",
    "                'transition': {'duration': 0}}],\n",
    "                'label': 'Pause',\n",
    "                'method': 'animate'\n",
    "            }\n",
    "        ],\n",
    "        'direction': 'left',\n",
    "        'pad': {'r': 10, 't': 87},\n",
    "        'showactive': False,\n",
    "        'type': 'buttons',\n",
    "        'x': 0.1,\n",
    "        'xanchor': 'right',\n",
    "        'y': 0,\n",
    "        'yanchor': 'top'\n",
    "    }\n",
    "]\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa97a15f3242c002ca32e24938d536e1fef4afc4"
   },
   "source": [
    "## Using bubble size as a variable\n",
    "\n",
    "Now we build on the above interactive graph by setting the size of the bubble as another variable we take the `Log GDP per capita`. \n",
    "The size of the bubble is controlled by the ```marker``` attribute of each trace.\n",
    "The marker should have the format:\n",
    "\n",
    "```python\n",
    "trace['marker'] = {\n",
    "    'sizemode': 'area',\n",
    "    'sizeref': int,\n",
    "    'size': list[int]\n",
    "}\n",
    "```\n",
    "\n",
    "First, we need to make sure that the bubble sizes don't blow up the plot but also that they aren't so tiny we cannot see them.\n",
    "So we probably want sizes from 1 to 500.\n",
    "So we take the `Log GDP per capita` and scale it to a range of 1 to 500.\n",
    "We also add in an exponential scale from the numpy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial.data_exploration_helper import get_happiness_data, get_clean_dataset_with_region\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "complete_happiness_df = get_clean_dataset_with_region(get_happiness_data())\n",
    "\n",
    "log_gdp_df = complete_happiness_df[['Country name', 'year', 'Log GDP per capita']]\n",
    "# get global min without 1\n",
    "log_gdp_df_without_1 = log_gdp_df[log_gdp_df['Log GDP per capita'] != 1]\n",
    "global_min_log_gdp_per_country = log_gdp_df_without_1['Log GDP per capita'].min()\n",
    "# replace 1 with global min\n",
    "log_gdp_df.loc[log_gdp_df['Log GDP per capita'] == 1, 'Log GDP per capita'] = global_min_log_gdp_per_country\n",
    "global_max_log_gdp_per_country = log_gdp_df['Log GDP per capita'].max()\n",
    "\n",
    "\n",
    "resized_log_gdp_df = log_gdp_df.copy()\n",
    "# Scale exponentially between 1 and 500\n",
    "resized_log_gdp_df['Resized Log GDP per capita'] = np.exp(log_gdp_df['Log GDP per capita']) * 500 / (np.exp(global_max_log_gdp_per_country) - np.exp(global_min_log_gdp_per_country))\n",
    "\n",
    "print(f\"Global min log GDP per country: {global_min_log_gdp_per_country}\")\n",
    "print(f\"Global max log GDP per country: {global_max_log_gdp_per_country}\")\n",
    "\n",
    "# append to final_happiness_df\n",
    "dataset = pd.merge(complete_happiness_df, resized_log_gdp_df, on=['Country name', 'year'], how='left')\n",
    "# Check out year 2010\n",
    "dataset[dataset['year'] == 2010].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": false,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from tutorial.data_exploration_helper import set_layout, full_clean_dataset\n",
    "from plotly.offline import iplot\n",
    "\n",
    "\n",
    "dataset = full_clean_dataset()\n",
    "x_column = 'Freedom to make life choices'\n",
    "y_column = 'Life Ladder'\n",
    "description_column = 'Country name'\n",
    "time_column = 'year'\n",
    "# Set the layout\n",
    "figure = set_layout(x_title='Freedom to make life choices', y_title='Life Ladder',\n",
    "            title='Happiness Indicators', x_logscale=False, y_logscale=False, \n",
    "            show_slider=True, slider_scale=years, show_button=True, show_legend=False, \n",
    "            height=650)\n",
    "\n",
    "# Define the new variable\n",
    "bubble_size_column = 'Resized Log GDP per capita'\n",
    "category_column = 'Regional indicator'\n",
    "\n",
    "\n",
    "\n",
    "# Make the grid\n",
    "years = dataset[time_column].unique()\n",
    "years.sort()\n",
    "    \n",
    "\n",
    "# Add the base frame\n",
    "year = min(years)\n",
    "trace = {\n",
    "    'x': list(dataset.loc[dataset['year'] == year, x_column]), \n",
    "    'y': list(dataset.loc[dataset['year'] == year, y_column]),\n",
    "    'mode': 'markers',\n",
    "    'text': list(dataset.loc[dataset['year'] == year, description_column]),\n",
    "    'marker': {\n",
    "        'size': list(dataset.loc[dataset['year'] == year, bubble_size_column]),\n",
    "        'sizemode': 'area',\n",
    "        'sizeref': 1,\n",
    "    },\n",
    "    'type': 'scatter'\n",
    "}\n",
    "figure['data'].append(trace)\n",
    "\n",
    "\n",
    "def frame_by_year_with_size(dataset, year, x_column, y_column, description_column):\n",
    "    \"\"\"Make a trace for a given year with bubble size\"\"\"\n",
    "    # Make a trace\n",
    "    trace = {\n",
    "        'x': list(dataset.loc[dataset['year'] == year, x_column]), \n",
    "        'y': list(dataset.loc[dataset['year'] == year, y_column]),\n",
    "        'mode': 'markers',\n",
    "        'text': list(dataset.loc[dataset['year'] == year, description_column]),\n",
    "        'marker': {\n",
    "            'size': list(dataset.loc[dataset['year'] == year, bubble_size_column]),\n",
    "            'sizemode': 'area',\n",
    "            'sizeref': 1,\n",
    "        },\n",
    "        'type': 'scatter'\n",
    "    }\n",
    "    frame = {\n",
    "        'data': [trace],\n",
    "        'name': str(year)\n",
    "    }\n",
    "    return frame\n",
    "\n",
    "\n",
    "# Add time frames\n",
    "figure['frames'] = [frame_by_year_with_size(dataset, year, x_column, y_column, description_column) for year in years]\n",
    "\n",
    "\n",
    "# Set the layout once more\n",
    "figure['layout']['xaxis']['range'] = [0, 1.2]\n",
    "figure['layout']['yaxis']['range'] = [0, 9]\n",
    "\n",
    "# Plot the animation\n",
    "iplot(figure, config={'scrollZoom': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22d5e9e25c7cad813ce9e41cfcdc7960e887d615"
   },
   "source": [
    "## Classify into categories\n",
    "\n",
    "Now we add a category variable, namely region indicator in our case.\n",
    "By default, if we split the traces into different categories they will all get different colours.\n",
    "So the figure structure changes in that the data of a frame or a figure is now a list of traces instead of just one.\n",
    "So we split the data by year for every frame and then by category for every trace.\n",
    "\n",
    "\n",
    "```python\n",
    "figure = {\n",
    "    'data': list[trace], # Split by category\n",
    "    'layout': {},\n",
    "    'frames': list[frame] # Split by year\n",
    "}\n",
    "\n",
    "frame = {\n",
    "    'data': list[trace],\n",
    "    'name': str,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Frames with category\n",
    "\n",
    "In the below exercise, complete the function to output a frame with the above format, so that it is is a dictionary with `'data'` and `'name'` where the\n",
    "\n",
    "1. `'data'` is a list of traces where every trace is the subset containing a specific category in the `'Regional indicator'` of the DataFrame.\n",
    "   Each trace should now also have the key `'name'` which is the category.\n",
    "3. `'name'` is equal to the year as a string.\n",
    "\n",
    "Take inspiration from above but now make the trace also a function dependent on the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tutorial.tests.testsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def solution_frames_with_category(dataset: pd.DataFrame, year: int, x_column: str, y_column: str, description_column: str, category_column: str, bubble_size_column: str) -> dict:\n",
    "    \"\"\"Make a frame for a given year with bubble size and color split the traces\n",
    "\n",
    "    Args:\n",
    "        dataset : DataFrame containing the happiness data\n",
    "        year : Year to plot\n",
    "        x_column : Column name for x-axis\n",
    "        y_column : Column name for y-axis\n",
    "        description_column : Column name for text\n",
    "\n",
    "    Returns:\n",
    "        - Dictionary containing the trace and frame information\n",
    "    \"\"\"\n",
    "    # Your code starts here\n",
    "    return\n",
    "    # Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00b65071453b5b16a3e67cc68ec6ab822ff331d4"
   },
   "source": [
    "So, we have finally generated the same interactive graph with our own dataset.\n",
    "Below is the full figure again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial.data_exploration_helper import load_full_happiness_figure\n",
    "from plotly.offline import iplot\n",
    "\n",
    "figure = load_full_happiness_figure()\n",
    "iplot(figure, config={'scrollZoom': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Exercise Fixing a library\n",
    "\n",
    "\n",
    "With huge and well-established libraries like pandas or numpy there are many contributers behind them and a lot of effort is spent to find any kind of bugs and mistakes.\n",
    "However, if you are browsing through possible libraries to use you might also find less well-maintained libraries, ones that may only have a single author and ones that haven't been touched in a while. \n",
    "\n",
    "Here we give you a direct example, this tutorial was inspired by the [bubbly](https://github.com/AashitaK/bubbly) package.\n",
    "However, with an update from the pandas library it is no longer compatible with newer versions of pandas and will through an error (see codeblock below). \n",
    "So what to do in that case?\n",
    "\n",
    "There are many options, you can inform the author of this problem on GitHub.\n",
    "Of course, they may not have time to fix this.\n",
    "You can find a different library, however, it might not be exactly the way you wanted it.\n",
    "You can downgrade your pandas library to be compatible, if you use pip show pandas you will see what version you have, it is possible to uninstall and reinstall a specific version.\n",
    "However, this might not be feasible if you need it in other places and is generally not a pretty solution. \n",
    "Last but not least you can try to fix it yourself.\n",
    "\n",
    "So as an exercise, we exported the bubbly library as a file `bubbly.py` into the folder `data.plotly_intro`.\n",
    "It is quite a short library so quite managable.\n",
    "Try to figure out what the error is exactly and then fix the library locally by modifying only the file `data/plotly_intro/bubbly.py` until the same code below compiles.\n",
    "\n",
    "Note: You will need to restart the kernel after changes to the packages.\n",
    "\n",
    "(If you are interested in a solution, we have a fixed version under tutorial.my_bubbly.py, feel free to check the differences.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from bubbly.bubbly import bubbleplot\n",
    "from data.data_exploration.bubbly import bubbleplot \n",
    "from plotly.offline import iplot\n",
    "path = \"data/data_exploration\"\n",
    "gapminder_indicators = pd.read_csv(path + '/gapminder.tsv', delimiter='\\t')\n",
    "\n",
    "figure = bubbleplot(dataset=gapminder_indicators, x_column='gdpPercap', y_column='lifeExp', \n",
    "    bubble_column='country', time_column='year', size_column='pop', color_column='continent', \n",
    "    x_title=\"GDP per Capita\", y_title=\"Life Expectancy\", title='Gapminder Global Indicators',\n",
    "    x_logscale=True, scale_bubble=3, height=650)\n",
    "iplot(figure, config={'scrollZoom': True})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
